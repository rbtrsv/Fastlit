{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import h2o\n",
    "from h2o.automl import H2OAutoML, get_leaderboard\n",
    "\n",
    "import mlflow\n",
    "import mlflow.h2o\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321. connected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-1.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-1 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-1 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-1 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table th,\n",
       "#h2o-table-1 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-1 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-1\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption></caption>\n",
       "    <thead></thead>\n",
       "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>53 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Europe/Bucharest</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.40.0.1</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>9 days</td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_robert_radoslav_lggrgs</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>2 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.11.0 final</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "--------------------------  --------------------------------------\n",
       "H2O_cluster_uptime:         53 secs\n",
       "H2O_cluster_timezone:       Europe/Bucharest\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.40.0.1\n",
       "H2O_cluster_version_age:    9 days\n",
       "H2O_cluster_name:           H2O_from_python_robert_radoslav_lggrgs\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    2 Gb\n",
       "H2O_cluster_total_cores:    8\n",
       "H2O_cluster_allowed_cores:  8\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://localhost:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.11.0 final\n",
       "--------------------------  --------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: experiment2\n",
      "Experiment_id: 2\n",
      "Artifact Location: file:///Users/robert.radoslav/Developer/main/finpy-containerized-app/finpy-api/ml_models/mlruns/2\n",
      "Lifecycle_stage: active\n",
      "Tracking uri: file:///Users/robert.radoslav/Developer/main/finpy-containerized-app/finpy-api/ml_models/mlruns\n"
     ]
    }
   ],
   "source": [
    "# Initiate H2O cluster\n",
    "h2o.init()\n",
    "\n",
    "# Initiate MLflow client\n",
    "client = MlflowClient()\n",
    "\n",
    "# Get parsed experiment name\n",
    "experiment_name = 'experiment2'\n",
    "\n",
    "# Create MLflow experiment\n",
    "try:\n",
    "    experiment_id = mlflow.create_experiment(experiment_name)\n",
    "    experiment = client.get_experiment_by_name(experiment_name)\n",
    "except:\n",
    "    experiment = client.get_experiment_by_name(experiment_name)\n",
    "\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "# Print experiment details\n",
    "print(f\"Name: {experiment_name}\")\n",
    "print(f\"Experiment_id: {experiment.experiment_id}\")\n",
    "print(f\"Artifact Location: {experiment.artifact_location}\")\n",
    "print(f\"Lifecycle_stage: {experiment.lifecycle_stage}\")\n",
    "print(f\"Tracking uri: {mlflow.get_tracking_uri()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n"
     ]
    }
   ],
   "source": [
    "# Import data directly as H2O frame (default location is data/processed)\n",
    "main_frame = h2o.import_file(path='health_insurance/data/processed/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('health_insurance/data/processed/train_col_types.json', 'w') as fp:\n",
    "        json.dump(main_frame.types, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'Response'\n",
    "predictors = [n for n in main_frame.col_names if n != target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML progress: |\n",
      "01:48:09.237: Project: AutoML_1_20230218_14809\n",
      "01:48:09.241: 5-fold cross-validation will be used.\n",
      "01:48:09.241: Setting stopping tolerance adaptively based on the training frame: 0.0033065124063248246\n",
      "01:48:09.241: Build control seed: 42\n",
      "01:48:09.243: training frame: Frame key: AutoML_1_20230218_14809_training_train.hex    cols: 208    rows: 91466  chunks: 32    size: 2477845  checksum: -277864416819399133\n",
      "01:48:09.243: validation frame: NULL\n",
      "01:48:09.243: leaderboard frame: NULL\n",
      "01:48:09.243: blending frame: NULL\n",
      "01:48:09.243: response column: Response\n",
      "01:48:09.243: fold column: null\n",
      "01:48:09.243: weights column: null\n",
      "01:48:09.261: Loading execution steps: [{XGBoost : [def_2 (1g, 10w), def_1 (2g, 10w), def_3 (3g, 10w), grid_1 (4g, 90w), lr_search (7g, 30w)]}, {GLM : [def_1 (1g, 10w)]}, {DRF : [def_1 (2g, 10w), XRT (3g, 10w)]}, {GBM : [def_5 (1g, 10w), def_2 (2g, 10w), def_3 (2g, 10w), def_4 (2g, 10w), def_1 (3g, 10w), grid_1 (4g, 60w), lr_annealing (7g, 10w)]}, {DeepLearning : [def_1 (3g, 10w), grid_1 (4g, 30w), grid_2 (5g, 30w), grid_3 (5g, 30w)]}, {completion : [resume_best_grids (6g, 60w)]}, {StackedEnsemble : [monotonic (9g, 10w), best_of_family_xglm (10g, 10w), all_xglm (10g, 10w)]}]\n",
      "01:48:09.291: Disabling Algo: DRF as requested by the user.\n",
      "01:48:09.291: Disabling Algo: GLM as requested by the user.\n",
      "01:48:09.293: AutoML job created: 2023.02.18 01:48:09.210\n",
      "01:48:09.293: AutoML build started: 2023.02.18 01:48:09.293\n",
      "01:48:09.308: AutoML: starting XGBoost_1_AutoML_1_20230218_14809 model training\n",
      "01:48:09.312: _train param, Dropping bad and constant columns: [Policy_Sales_Channel_2, Policy_Sales_Channel_28, Policy_Sales_Channel_82]\n",
      "01:48:09.313: _response param, We have detected that your response column has only 2 unique values (0/1). If you wish to train a binary model instead of a regression model, convert your target column to categorical before training.\n",
      "\n",
      "██\n",
      "01:48:45.486: AutoML: starting GBM_1_AutoML_1_20230218_14809 model training\n",
      "01:48:45.488: _train param, Dropping bad and constant columns: [Policy_Sales_Channel_2, Policy_Sales_Channel_28, Policy_Sales_Channel_82]\n",
      "01:48:45.488: _response param, We have detected that your response column has only 2 unique values (0/1). If you wish to train a binary model instead of a regression model, convert your target column to categorical before training.\n",
      "\n",
      "████\n",
      "01:49:43.186: AutoML: starting XGBoost_2_AutoML_1_20230218_14809 model training\n",
      "01:49:43.187: _train param, Dropping bad and constant columns: [Policy_Sales_Channel_2, Policy_Sales_Channel_28, Policy_Sales_Channel_82]\n",
      "01:49:43.187: _response param, We have detected that your response column has only 2 unique values (0/1). If you wish to train a binary model instead of a regression model, convert your target column to categorical before training.\n",
      "\n",
      "██\n",
      "01:50:07.222: AutoML: starting GBM_2_AutoML_1_20230218_14809 model training\n",
      "01:50:07.223: _train param, Dropping bad and constant columns: [Policy_Sales_Channel_2, Policy_Sales_Channel_28, Policy_Sales_Channel_82]\n",
      "01:50:07.223: _response param, We have detected that your response column has only 2 unique values (0/1). If you wish to train a binary model instead of a regression model, convert your target column to categorical before training.\n",
      "\n",
      "███\n",
      "01:50:35.4: AutoML: starting GBM_3_AutoML_1_20230218_14809 model training\n",
      "01:50:35.5: _train param, Dropping bad and constant columns: [Policy_Sales_Channel_2, Policy_Sales_Channel_28, Policy_Sales_Channel_82]\n",
      "01:50:35.5: _response param, We have detected that your response column has only 2 unique values (0/1). If you wish to train a binary model instead of a regression model, convert your target column to categorical before training.\n",
      "\n",
      "█\n",
      "01:51:11.291: AutoML: starting GBM_4_AutoML_1_20230218_14809 model training\n",
      "01:51:11.291: _train param, Dropping bad and constant columns: [Policy_Sales_Channel_2, Policy_Sales_Channel_28, Policy_Sales_Channel_82]\n",
      "01:51:11.291: _response param, We have detected that your response column has only 2 unique values (0/1). If you wish to train a binary model instead of a regression model, convert your target column to categorical before training.\n",
      "\n",
      "█\n",
      "01:51:46.535: AutoML: starting XGBoost_3_AutoML_1_20230218_14809 model training\n",
      "01:51:46.536: _train param, Dropping bad and constant columns: [Policy_Sales_Channel_2, Policy_Sales_Channel_28, Policy_Sales_Channel_82]\n",
      "01:51:46.536: _response param, We have detected that your response column has only 2 unique values (0/1). If you wish to train a binary model instead of a regression model, convert your target column to categorical before training.\n",
      "\n",
      "█\n",
      "01:51:59.297: AutoML: starting GBM_5_AutoML_1_20230218_14809 model training\n",
      "01:51:59.298: _train param, Dropping bad and constant columns: [Policy_Sales_Channel_2, Policy_Sales_Channel_28, Policy_Sales_Channel_82]\n",
      "01:51:59.298: _response param, We have detected that your response column has only 2 unique values (0/1). If you wish to train a binary model instead of a regression model, convert your target column to categorical before training.\n",
      "\n",
      "██\n",
      "01:52:24.742: AutoML: starting DeepLearning_1_AutoML_1_20230218_14809 model training\n",
      "01:52:24.743: _train param, Dropping bad and constant columns: [Policy_Sales_Channel_2, Policy_Sales_Channel_28, Policy_Sales_Channel_82]\n",
      "01:52:24.743: _response param, We have detected that your response column has only 2 unique values (0/1). If you wish to train a binary model instead of a regression model, convert your target column to categorical before training.\n",
      "01:52:24.796: DeepLearning_1_AutoML_1_20230218_14809 [DeepLearning def_1] failed: water.exceptions.H2OModelBuilderIllegalArgumentException: Illegal argument(s) for DeepLearning model: DeepLearning_1_AutoML_1_20230218_14809_cv_1.  Details: ERRR on field: _balance_classes: balance_classes requires classification.\n",
      "\n",
      "01:52:24.799: AutoML: starting XGBoost_grid_1_AutoML_1_20230218_14809 hyperparameter search\n",
      "\n",
      "█████ (failed)\n",
      "\n",
      "01:53:07.944: AutoML build stopped: 2023.02.18 01:53:07.944\n",
      "01:53:07.944: AutoML build done: built 0 models\n",
      "01:53:07.944: AutoML duration:  4 min 58.651 sec\n",
      "01:53:07.951: Empty leaderboard.\n",
      "AutoML was not able to build any model within a max runtime constraint of 0 seconds, you may want to increase this value before retrying.\n",
      "\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Job with key $03017f00000132d4ffffffff$_bfa9e39404193b0a21e2dff38b564c7e failed with an exception: water.exceptions.H2OAutoMLException: Aborting AutoML after too many consecutive model failures\nstacktrace: \nwater.exceptions.H2OAutoMLException: Aborting AutoML after too many consecutive model failures\n\tat ai.h2o.automl.AutoML.learn(AutoML.java:776)\n\tat ai.h2o.automl.AutoML.run(AutoML.java:494)\n\tat ai.h2o.automl.H2OJob$1.compute2(H2OJob.java:33)\n\tat water.H2O$H2OCountedCompleter.compute(H2O.java:1677)\n\tat jsr166y.CountedCompleter.exec(CountedCompleter.java:468)\n\tat jsr166y.ForkJoinTask.doExec(ForkJoinTask.java:263)\n\tat jsr166y.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:976)\n\tat jsr166y.ForkJoinPool.runWorker(ForkJoinPool.java:1479)\n\tat jsr166y.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:104)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 12\u001b[0m\n\u001b[1;32m      2\u001b[0m aml \u001b[39m=\u001b[39m H2OAutoML(\n\u001b[1;32m      3\u001b[0m                 max_models\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, \u001b[39m# Run AutoML for n base models\u001b[39;00m\n\u001b[1;32m      4\u001b[0m                 seed\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m                 exclude_algos \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mGLM\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mDRF\u001b[39m\u001b[39m'\u001b[39m], \u001b[39m# Specify algorithms to exclude\u001b[39;00m\n\u001b[1;32m      9\u001b[0m             )\n\u001b[1;32m     11\u001b[0m \u001b[39m# Initiate AutoML training\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m aml\u001b[39m.\u001b[39;49mtrain(x\u001b[39m=\u001b[39;49mpredictors, y\u001b[39m=\u001b[39;49mtarget, training_frame\u001b[39m=\u001b[39;49mmain_frame)\n\u001b[1;32m     14\u001b[0m \u001b[39m# Set metrics to log\u001b[39;00m\n\u001b[1;32m     15\u001b[0m mlflow\u001b[39m.\u001b[39mlog_metric(\u001b[39m\"\u001b[39m\u001b[39mlog_loss\u001b[39m\u001b[39m\"\u001b[39m, aml\u001b[39m.\u001b[39mleader\u001b[39m.\u001b[39mlogloss())\n",
      "File \u001b[0;32m~/Developer/main/finpy-containerized-app/env311/lib/python3.11/site-packages/h2o/automl/_estimator.py:679\u001b[0m, in \u001b[0;36mH2OAutoML.train\u001b[0;34m(self, x, y, training_frame, fold_column, weights_column, validation_frame, leaderboard_frame, blending_frame)\u001b[0m\n\u001b[1;32m    677\u001b[0m poll_updates \u001b[39m=\u001b[39m ft\u001b[39m.\u001b[39mpartial(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_poll_training_updates, verbosity\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_verbosity, state\u001b[39m=\u001b[39m{})\n\u001b[1;32m    678\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 679\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_job\u001b[39m.\u001b[39;49mpoll(poll_updates\u001b[39m=\u001b[39;49mpoll_updates)\n\u001b[1;32m    680\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    681\u001b[0m     poll_updates(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_job, \u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/Developer/main/finpy-containerized-app/env311/lib/python3.11/site-packages/h2o/job.py:90\u001b[0m, in \u001b[0;36mH2OJob.poll\u001b[0;34m(self, poll_updates)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstatus \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mFAILED\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m     89\u001b[0m     \u001b[39mif\u001b[39;00m (\u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjob, \u001b[39mdict\u001b[39m)) \u001b[39mand\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39mstacktrace\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mlist\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjob)):\n\u001b[0;32m---> 90\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mJob with key \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m failed with an exception: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mstacktrace: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     91\u001b[0m                                \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjob_key, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexception, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjob[\u001b[39m\"\u001b[39m\u001b[39mstacktrace\u001b[39m\u001b[39m\"\u001b[39m]))\n\u001b[1;32m     92\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     93\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mJob with key \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m failed with an exception: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjob_key, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexception))\n",
      "\u001b[0;31mOSError\u001b[0m: Job with key $03017f00000132d4ffffffff$_bfa9e39404193b0a21e2dff38b564c7e failed with an exception: water.exceptions.H2OAutoMLException: Aborting AutoML after too many consecutive model failures\nstacktrace: \nwater.exceptions.H2OAutoMLException: Aborting AutoML after too many consecutive model failures\n\tat ai.h2o.automl.AutoML.learn(AutoML.java:776)\n\tat ai.h2o.automl.AutoML.run(AutoML.java:494)\n\tat ai.h2o.automl.H2OJob$1.compute2(H2OJob.java:33)\n\tat water.H2O$H2OCountedCompleter.compute(H2O.java:1677)\n\tat jsr166y.CountedCompleter.exec(CountedCompleter.java:468)\n\tat jsr166y.ForkJoinTask.doExec(ForkJoinTask.java:263)\n\tat jsr166y.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:976)\n\tat jsr166y.ForkJoinPool.runWorker(ForkJoinPool.java:1479)\n\tat jsr166y.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:104)\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run():\n",
    "        aml = H2OAutoML(\n",
    "                        max_models=5, # Run AutoML for n base models\n",
    "                        seed=42, \n",
    "                        balance_classes=True, # Target classes imbalanced, so set this as True\n",
    "                        sort_metric='logloss', # Sort models by logloss (metric for multi-classification)\n",
    "                        verbosity='info', # Turn on verbose info\n",
    "                        exclude_algos = ['GLM', 'DRF'], # Specify algorithms to exclude\n",
    "                    )\n",
    "        \n",
    "        # Initiate AutoML training\n",
    "        aml.train(x=predictors, y=target, training_frame=main_frame)\n",
    "        \n",
    "        # Set metrics to log\n",
    "        mlflow.log_metric(\"log_loss\", aml.leader.logloss())\n",
    "        mlflow.log_metric(\"AUC\", aml.leader.auc())\n",
    "        \n",
    "        # Log and save best model (mlflow.h2o provides API for logging & loading H2O models)\n",
    "        mlflow.h2o.log_model(aml.leader, artifact_path=\"model\")\n",
    "        \n",
    "        model_uri = mlflow.get_artifact_uri(\"model\")\n",
    "        print(f'AutoML best model saved in {model_uri}')\n",
    "        \n",
    "        # Get IDs of current experiment run\n",
    "        exp_id = experiment.experiment_id\n",
    "        run_id = mlflow.active_run().info.run_id\n",
    "        \n",
    "        # Save leaderboard as CSV\n",
    "        lb = get_leaderboard(aml, extra_columns='ALL')\n",
    "        lb_path = f'health_insurance/mlruns/{exp_id}/{run_id}/artifacts/model/leaderboard.csv'\n",
    "        lb.as_data_frame().to_csv(lb_path, index=False) \n",
    "        print(f'AutoML Complete. Leaderboard saved in {lb_path}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fecfb9b2b6c378f848f6245ebc99eeea625117fd7c00d4f4be497952a18b99e6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
